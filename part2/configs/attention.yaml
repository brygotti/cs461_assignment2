model:
  class_path: models.attention.Attention
  args:
    embed_dim: 3072
    latent_dim: 1024
    num_classes: 7
    multi_head: false

  best_weight_path: ckpts/best_attention_model.pt

dataset:
  collate_fn: models.attention.attention_collate_fn
